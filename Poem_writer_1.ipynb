{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5kK5hU4yDST",
        "outputId": "6e4be974-a587-4f13-9bcb-1c11b5997e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk"
      ],
      "metadata": {
        "id": "LwGR-kQP8FZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" You are a renowned poet and song-writer in English Literature. you can generate rhyming stanzas based on a theme (e.g., 'Love', 'Space', 'Coding'). write a poem on 'Nature'\""
      ],
      "metadata": {
        "id": "NAA-b_0K8JlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Generate text\n",
        "output_fast = fast_generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(output_fast[0]['generated_text'])"
      ],
      "metadata": {
        "id": "hCtA7uMO8cxX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "e3f23d51b28b477e9b4c2432c61abe62",
            "575e8344271f4b1e8f281fa12ac6c103",
            "a7cc7b812d7d471080c00f971909bf43",
            "2f701a17ccf94535a4239b620b07ad3d",
            "646ee61c638942c8ad065aef3c69be13",
            "3588fcd17ac047f9b811260a62400541",
            "9e7bedc45b9e4eefb0793a1a86a92b6a",
            "a4fcd30d863c4899a66519de97069f59",
            "5b66753537b743b990e3b59f2d01ae27",
            "3eb1059fd0c64845bf9d712965dd88c7",
            "cf28af0c09e24053b449745c3ee86d96",
            "9687ecd426d64c0cba34a9dd338911ba",
            "6bf49bf7c8a248be9d687ad4ba261b7f",
            "e59439d4a90549af8f0df35d03b68a35",
            "2ab2a92418b0406db0bc5a93278c28cc",
            "94abe9f1e2c34538951047a6407ff14e",
            "0245adb6d70c41cf886a10435984f070",
            "f516652c125a4f53979d68e62cc0fa46",
            "442c3782295c45838b9d45b20a3b55c6",
            "bc62d6d919ae4517a734f4590e0f93d4",
            "808bd5d2eaa142bebe71d0557856cf25",
            "e57c03041f2a4bf1b9155fb2e23f8dd8",
            "fa2766ad1cd04ea8a9967be44bc6943c",
            "7c2cfdc62fbc40f7b55b1cf306e91163",
            "c13b7774e5134d208d1ab6e379168462",
            "5074b417d91042aba10682246f0393b7",
            "c3363fcc079e4b5db1bab65e423728e0",
            "8ffffc3d89df46e79603e4b86e30479d",
            "639c856b0b3a46ea8318fa349d6d637b",
            "66aca165cce94682ba04a229011a3871",
            "eaac14cd97514a5db463f105cb8d43b4",
            "e5bd9cdc40944591873b4271b2c66e76",
            "80e5d77d43b5421a95d1ad1e3e96c211",
            "8973f3331945405e8b0db3633f3183cd",
            "1bdfe0ec919c40669a1d8f8eeda3f044",
            "b031604500c147f184e20c63136944c8",
            "27e780ce6b084ba5baefe2e01a7383e7",
            "7c0ed5004fc94dddb9df63c4bdb70016",
            "f673c38d2bcc482a8d0f188b95722503",
            "0cbf5f2a10274bd19b601f1643dfeb30",
            "6c0b183e6cfa4d68bb92424ed4e575b0",
            "3b471388f6004c90b888b67642fa6fb0",
            "18f1ef71dec1439b8986ad8634de0681",
            "911cab5a805a494a88d7f87cc5e3c293",
            "19b8ddfe3a1044d794f13452515dfb2c",
            "e32d82a3e6eb435cbdb9443c2c34a8fc",
            "04d6d521d08f4f7b902df862bcd754b8",
            "b0a3681dc35945df88afb7d7738c850f",
            "93efa267c2cf40e788acc44d5e2533cd",
            "5c17f6d9373841ad9040df97bae0f090",
            "1eeb0db1317744999275f4cb273e88a3",
            "56b4a39936f44b96866319df173c58a4",
            "184205288ac042eb8bfca332a805b95e",
            "b095a315f14646848e6bb9273a8114b3",
            "240af3c8ce5b4cd290532b907cd5b589",
            "1ca3469f7c764441ba0f8a44ad6e7e80",
            "b2b9fd17bf694caf867b07cad8c7fdc5",
            "6c22a0e5cf964d2ca99ed66c0f243d82",
            "979cbdc549b6487cb66449662bcb51c1",
            "7b38240166b14695a3185e06ff6082c3",
            "b9b99867341144739d012c38c8a9e119",
            "73f4c79e323a4aa0aeb89eaa9964948b",
            "6736f51730d04b798f81d5d5d65b7eb8",
            "c58343a5fdfa4b6fb724be757d48f55e",
            "7d8ec7085c1544b7a991a9da70e1e252",
            "86e35c575edd4b5392c109e9079dd6c8",
            "eb13e88f1ab942fabd9900f84bb55b94",
            "ece6c52e164a479386585ccae0584a06",
            "f836646a2fc9405491e38f927a78a70d",
            "88e0c53a812844e89c5c1dbe2dad1970",
            "10510354b46c4a98b2000f4d4a9cab71",
            "1829da569e744675ad90b5e145babeef",
            "038b5619577c4333a5484376be2c5834",
            "59db34f37f5145c1b914eb00e30db652",
            "8cb55ebdc80247fda4c29a1478995dab",
            "3d59e41b1291423b955f4cd3b243c19c",
            "19ad1ccc75c8411b95b6a83227c7a572"
          ]
        },
        "outputId": "c9ec9700-834c-4716-8641-f868e9f363dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3f23d51b28b477e9b4c2432c61abe62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9687ecd426d64c0cba34a9dd338911ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa2766ad1cd04ea8a9967be44bc6943c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8973f3331945405e8b0db3633f3183cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19b8ddfe3a1044d794f13452515dfb2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ca3469f7c764441ba0f8a44ad6e7e80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb13e88f1ab942fabd9900f84bb55b94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You are a renowned poet and song-writer in English Literature. you can generate rhyming stanzas based on a theme (e.g., 'Love', 'Space', 'Coding'). write a poem on 'Hell' (e.g., 'The night of the Angels') so that it is written in a rhyme style. You can use the 'Hell' word to express your love. You may be able to write your poem without rhyming. You can write your poem in a's.o.l.t.o.o.o' format. You can write a poem in a double-spaced format with the's' word. You may also write a poem in a double-spaced format with the 'o' word. You may also write your poem using the 'o' word. Some poems are written according to the rules of grammar, so you may have to use a number of rules to make your poem readable, but you can have at least one rule in place which might not be present in many other poems.\n",
            "\n",
            "You may have to use a number of rules to make your poem readable, but you can have at least one rule in place which might not be present in many other poems. If you are writing in a double-spaced format, use the 'o' word. Instead of using a single rule, you can use a number of rules to make your poem readable. You may also use a few rules to make\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"write a poem on 'Hell'\""
      ],
      "metadata": {
        "id": "9GguLgDih4sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_generator = pipeline('text-generation', model='gpt2-medium')\n",
        "\n",
        "# Generate text\n",
        "output_fast = fast_generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(output_fast[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pycv2RzQi4Ru",
        "outputId": "e58c29d7-8879-43a4-dc57-e2dd96915221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write a poem on 'Hell'\n",
            "\n",
            "\n",
            "(Image: Getty)\n",
            "\n",
            "The idea of sending in the troops was first raised by the likes of Sir Winston Churchill and Tony Blair, but in the end it fell on deaf ears.\n",
            "\n",
            "The idea first came up on a radio show in the 1980s, when former soldiers who wanted to use their experience to write poems were told to try and get their poems heard by the likes of Jimi Hendrix.\n",
            "\n",
            "Sir Winston said: \"I'm going to get my own poem on the air that's a little bit about the idea of hell.\n",
            "\n",
            "\"It's not a poem about heaven â€“ it's a poem about hell.\"\n",
            "\n",
            "The idea was also raised by a former SAS commander and was eventually followed by a member of the Royal Air Force and the Duke of Edinburgh.\n",
            "\n",
            "It was also included in another programme in the late 1990s, but was never put to the test.\n",
            "\n",
            "The poem, titled 'Hell,' was written by a man called Tim O'Donnell, but it's believed he was inspired by the poem 'The Man Who Smiled at the End' by the author Stephen Daldry.\n",
            "\n",
            "Tim said: \"It's a poem about a soldier who is in a position to make a choice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_generator = pipeline('text-generation', model='EleutherAI/gpt-neo-125M')\n",
        "\n",
        "# Generate text\n",
        "output_fast = fast_generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(output_fast[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "067ac29c2bff4bbe926d43a3d1d81e3d",
            "8591ee008bee43dcb20f49ef9d4c764c",
            "9bea2d601df34e52b38a0f1d1bc129b4",
            "9397bdbd6a034303970e648ad54c9ad1",
            "04789466fbaf49e4aec9eab5b96a19d7",
            "20665f2fd9be437a92bb3e5ccf3ad1ac",
            "6866a905002f460eb90d1773e804b6ba",
            "735f1b76d2364f428f990844f9f413fe",
            "879ad99725464eaf82aadcaa9f54bcf6",
            "c252225b2fd14d5a8b3ad40d9a0ffbf7",
            "f08a5865d7ba4e76a7f31905e87608bc",
            "d55c0b038f1c44b08f38d200e956ae87",
            "6a55c7637ce54d48a15fc77924f763bb",
            "df0dd70c7820428cacd706461e8dd79a",
            "22f795e84edb46e18302d2994ae5ce4d",
            "004a465456f9449ca730789f7679c7d9",
            "f3b6ad5f8b114daeb42324cfdc0d597a",
            "fae6bba9528c449c80c613ebdbb0a9bf",
            "d1559d610c7348bcb037a7e74ca184a6",
            "5197f7a5cbfb43c7b69ea19a518308f0",
            "997df6ebe4e74ab295d194ed5696434a",
            "137d7cf03ef64cdbbfaf00e4c7d04d9e",
            "95af2805b6f243418dac00e61b7c9d00",
            "34cd43b3387347f2a1ab9bc05b4a3941",
            "12e17e2fcb65418496c89b1240531aa4",
            "0308139ad76443dab0709f9937a661d6",
            "57ece3677de0477fa4e1c7f3af8fb9b0",
            "dedae9a261f74879b7aa99050b0f54e8",
            "ce4712f022d24c2b9bd5294ce2bf50a9",
            "6ad4e8a59e1e4b0a9a88c579cdadb4e1",
            "341d48efff1e45adb115b67ca6a5a137",
            "81df697008964e66bd92fa6a8e7b4977",
            "f3d6b124cb654257afdb64e69a8b7441",
            "4275e3b626814050a380a88193dfc7a6",
            "3bf7a80d4b304136a5cb7a8ad61a2c2d",
            "72a50a3c2059477698ca9475a989a1e0",
            "75e936e51d0647dda9f0371f716af036",
            "0a52c07e1b1b42f39dfea7450500f873",
            "0d89c83a23b941b58b5b176cc57d7802",
            "01bb649c484e4bfeaf2e4b3a8957709a",
            "bf7caf00f4b544089aa0785667ad6b64",
            "0d433cb24ab14a23ad52b7abad900d11",
            "f8293dfbeacc428492fd65297dd5b1bc",
            "86e857b50a9b4212a35665b487614864",
            "ed575b0bfcf0407a97af2253205992ed",
            "b1221b38023a43af99e564a1c639521a",
            "3eaacd09931347bc8c098f27ed8d2ca3",
            "108393d92a3647c8b9136805b2f85b32",
            "2857c069bffb4fbb8f37f8eb67ad3c88",
            "ee34e72c81724b66907aef29288a49d6",
            "6b37ef8247d641d4b8db902cd998400d",
            "d72c2cb289264c5cb1f5d24a3fe02e92",
            "19b42d3fea624e2887e221cc407afbc8",
            "d305600f10d543fc9cc28e89951344ab",
            "5f288b7fc29841c99efd4b6ec82a5965",
            "1595b7ed692e4b4b854b0f2ea5f9de07",
            "bbd677452b854bf2b5cf7446b3a43e64",
            "b7f16cdfcd8e44d090ecbe74a077e7b5",
            "edc92859e06f4362a5652b2c5b05d90d",
            "cf73c736ce414ac8b5c276061ab308b8",
            "0a56f76d3d1f4002afe0e6acff85de23",
            "6da7cbcc68d54ef1a2056c6d47edab17",
            "67a135f780b8499f87e1d812da3dca97",
            "00adf51e6b0744929198c68a615520e1",
            "416391d556c040e59ae1ae43554c9093",
            "b6b4429341fb4bbda0944150ee95a78b",
            "d7ec7bc900c246969818439110642bec",
            "f4579ed26dca48ab87ea7c4b45fed2bb",
            "47736ae4e88d442583da4796f81971bc",
            "542c0d6e60274c1a9ed7271d15644f08",
            "1dd5e781535c441cba2cbbf6bb74541e",
            "3a65e65f367d474c8b310ecb97c2604c",
            "6ff848d060184c14bcd867eabb971eb3",
            "96d7be947a17448e8c0247b345812e55",
            "3bc3a566de144f9bbef69330723d48b1",
            "a83006d0268f41c2bab1691b7274aae1",
            "865777cbd88e489f876859d12f0bbc89",
            "b9cc68a8fcf149c2be2b49d99be9ffd7",
            "4f1e477854684a04b3ebdafcc36ae714",
            "410d9feaf3034d14b352f1fc7ba09b85",
            "e24ff852c8404886b84039b1d3f4a7f8",
            "574c4435f5f649bc8c804535b51e1d77",
            "c956f092f4d44aad9e0a2cfe5ff51cbb",
            "a58ce09f3f5c41c4961361117b721a93",
            "f976ed9d59634719b14809a7871dd4a1",
            "a2ee4875eb4449d1ba35771d1d2188aa",
            "06cd220022d04429bb1eef6e325924fd",
            "edeb70a7c9104f91972f4d8fdebc90aa"
          ]
        },
        "id": "4YxrnEHPi5I-",
        "outputId": "3f4d5dd0-b9f7-4991-d02d-a4a339563276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "067ac29c2bff4bbe926d43a3d1d81e3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d55c0b038f1c44b08f38d200e956ae87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95af2805b6f243418dac00e61b7c9d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4275e3b626814050a380a88193dfc7a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed575b0bfcf0407a97af2253205992ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1595b7ed692e4b4b854b0f2ea5f9de07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ec7bc900c246969818439110642bec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9cc68a8fcf149c2be2b49d99be9ffd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write a poem on 'Hell'\n",
            "\n",
            "(You may choose which one I like best.)\n",
            "\n",
            "\"You just don't understand how I do it.\"\n",
            "\n",
            "\"I'm not going to be anybody's prisoner.\"\n",
            "\n",
            "\"You don't really understand. And you don't think I know anything about you.\"\n",
            "\n",
            "\"If you have any knowledge, you're not going to be allowed to do anything I don't want you to do.\"\n",
            "\n",
            "\"Not until you tell me what you want to do.\"\n",
            "\n",
            "\"You don't understand that I'm not going to be anybody's prisoner.\"\n",
            "\n",
            "\"How about if I tell you what I want to do?\"\n",
            "\n",
            "\"If you tell me what I want to do, then I'll be responsible.\"\n",
            "\n",
            "\"You don't understand.\"\n",
            "\n",
            "\"Yes, you do, but I'm not going to be responsible.\"\n",
            "\n",
            "\"You don't understand.\"\n",
            "\n",
            "\"You're not going to be responsible.\"\n",
            "\n",
            "\"I know what I want to do. I'm not going to be responsible.\"\n",
            "\n",
            "\"You're not going to be responsible.\"\n",
            "\n",
            "\"You're not going to be responsible.\"\n",
            "\n",
            "\"You're not going to be responsible.\"\n",
            "\n",
            "\"What if you tell me what\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IB6D67RRk6bg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
